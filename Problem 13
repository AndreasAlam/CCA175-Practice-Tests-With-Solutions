Instructions
Copy all h1b data from HDFS to Hive table excluding those where year is NA or prevailing_wage is NA

Data Description
h1b data with ascii null "\0" as delimiter is available in HDFS

h1b data information:

HDFS Location: /public/h1b/h1b_data_noheader
Fields:
ID, CASE_STATUS, EMPLOYER_NAME, SOC_NAME, JOB_TITLE, FULL_TIME_POSITION, PREVAILING_WAGE, YEAR, WORKSITE, LONGITUDE, LATITUDE
Ignore data where PREVAILING_WAGE is NA or YEAR is NA
PREVAILING_WAGE is 7th field
YEAR is 8th field
Number of records matching criteria: 3002373
Output Requirements
Save it in Hive Database
Create Database: CREATE DATABASE IF NOT EXISTS `whoami`
Switch Database: USE `whoami`
Save data to hive table h1b_data
Create table command:

CREATE TABLE h1b_data (
  ID                 INT,
  CASE_STATUS        STRING,
  EMPLOYER_NAME      STRING,
  SOC_NAME           STRING,
  JOB_TITLE          STRING,
  FULL_TIME_POSITION STRING,
  PREVAILING_WAGE    DOUBLE,
  YEAR               INT,
  WORKSITE           STRING,
  LONGITUDE          STRING,
  LATITUDE           STRING
)
                
Replace `whoami` with your OS user name

Sol:

h1b_raw = spark.read.format('csv').option('sep','\0').load('/public/h1b/h1b_data')
h1b_stage = h1b_raw.where("_c6!='NA' AND _c7!='NA'")
h1b_stage.count()
h1b_stage.createOrReplaceTempView('h1b_stage')
spark.sql("DROP TABLE swarajnewar.h1b_data")
spark.sql("create table swarajnewar.h1b_data(ID INT,CASE_STATUS STRING,EMPLOYER_NAME STRING,SOC_NAME STRING,JOB_TITLE STRING,FULL_TIME_POSITION STRING,PREVAILING_WAGE DOUBLE,YEAR INT,WORKSITE STRING,LONGITUDE STRING,LATITUDE STRING)")
spark.sql("INSERT INTO swarajnewar.h1b_data select * from h1b_data")
